{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANUJA TAYAL\n",
    "#\n",
    "# Problem Statement:\n",
    "# Question answering system for a text article\n",
    "# \n",
    "# Method of Solution\n",
    "# - The application is designed to answer questions on an artical specifically Wikipedia/article using Gensim module of Doc2vec.\n",
    "# - The application is designed in form of a chatbot which greets with hi and you can answer as many questions \n",
    "#   till you thank him for his services.\n",
    "# - The application reads the article, preprocesses it to remove punctuations and other irrelevant texts. \n",
    "#   The processed text then trains the model using Doc2vec which converts every sentence of article to its corresponding vector. \n",
    "# - When the application is asked a question most probably a fact based question, question is preprocessed and \n",
    "#   trained model calculates calculates the corresponding Doc2vec vector. \n",
    "# - And the application returns the most similar sentence from the model and also the similarity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing text by removing links, removing anything except numbers,letters,-,. and remove extra white spaces\n",
    "def preprocess(text):\n",
    "    text=re.sub(r'[^a-zA-Z-0-9.]',' ',text) #remove anything except numbers,letters,-,.\n",
    "    text=re.sub(r'\\s+',' ',text)    #remove extra white spaces\n",
    "    return text #return processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read the article, process it and tokenize them to sentences\n",
    "with open('document.txt') as f:\n",
    "    text=f.read()\n",
    "\n",
    "text=preprocess(text)\n",
    "sent_list=nltk.sent_tokenize(text) #tokenize text to sentences\n",
    "# print(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize sentences to individual words of sentences and also remove stopwords\n",
    "# words1=[nltk.word_tokenize(sent.lower()) for sent in sent_list]\n",
    "words1=[]\n",
    "for sent in sent_list:\n",
    "    if sent!='.':\n",
    "        words1.append(nltk.word_tokenize(sent.lower()))\n",
    "# print(words1)\n",
    "for i in range(len(words1)):  \n",
    "    words1[i] = [w for w in words1[i] if w not in stopwords.words('english')]\n",
    "# # print(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Doc2vec to create a vector from the \n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(words1)]\n",
    "model = Doc2Vec(vector_size=100, window=10, min_count=1, workers=4)\n",
    "model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the modell with 100 epochs\n",
    "max_epochs=100\n",
    "for epoch in range(max_epochs):\n",
    "#     print('iteration {0}'.format(epoch))\n",
    "    model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)\n",
    "    model.alpha -= 0.0002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greet the user\n",
    "greeting_input_texts = (\"hi\",\"hey\", \"heys\", \"hello\", \"morning\", \"evening\",\"greetings\",)\n",
    "greeting_replie_texts = [\"hey\", \"hey hows you?\", \"*nods*\", \"hello there\", \"ello\", \"Welcome, how are you\"]\n",
    " \n",
    "def reply_greeting(text):\n",
    "    for word in text.split():\n",
    "        if word.lower() in greeting_input_texts:\n",
    "            return random.choice(greeting_replie_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give reply function that takes user input and returns required most similar sentence and the similarity number\n",
    "def give_reply(user_input):\n",
    "    chatbot_response=''\n",
    "    user_input=preprocess(user_input) #preprocess user input\n",
    "    user_sent=nltk.word_tokenize(user_input.lower()) #tokenize user sentence\n",
    "#     print(user_input,user_sent)\n",
    "    input_vector=model.infer_vector(user_sent) #infer the vector from the trained model\n",
    "    sims = model.docvecs.most_similar([input_vector], topn=len(model.docvecs))\n",
    "    sent_index1,sent_index2=sims[0][0],sims[1][0] #extract 2 most similar sentence\n",
    "    return (sent_list[sent_index1],sent_list[sent_index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a chatbot and will answer your queries regarding the article:\n",
      "What is the difference between the approaches of Socrates and Aristotle?\n",
      "Chatbot: ('Plato believed that talent and intelligence are not distributed genetically and thus is be found in children born to all classes although his proposed system of selective public education for an educated minority of the population does not really follow a democratic model.', 'Aristotle considered human nature habit and reason to be equally important forces to be cultivated in education the ultimate aim of which should be to produce good and virtuous citizens.')\n",
      "Why do educationists consider philosophy a ‘weak and woolly’ field?\n",
      "Chatbot: ('Many educationalists consider it a weak and woolly field too far removed from the practical applications of the real world to be useful.', 'Philosophy of Education is a label applied to the study of the purpose process nature and ideals of education.')\n",
      "What do you understand by the term ‘Perennialism’, in the context of the given comprehension passage?\n",
      "Chatbot: ('But philosophers dating back to Plato and the Ancient Greeks have given the area much thought and emphasis and there is little doubt that their work has helped shape the practice of education over the millennia.', 'During the Medieval period the idea of Perennialism was first formulated by St. Thomas Aquinas in his work De Magistro .')\n",
      "Were Plato’s beliefs about education democratic?\n",
      "Chatbot: ('He believed that education should be holistic including facts skills physical discipline music and art.', 'But philosophers dating back to Plato and the Ancient Greeks have given the area much thought and emphasis and there is little doubt that their work has helped shape the practice of education over the millennia.')\n",
      "Why did Aquinas propose a model of education which did not lay much emphasis on facts?\n",
      "Chatbot: ('He emphasized the balancing of the theoretical and practical aspects of subjects taught among which he explicitly mentions reading writing mathematics music physical education literature history and a wide range of sciences as well as play which he also considered important.', 'Perennialism holds that one should teach those things deemed to be of everlasting importance to all people everywhere namely principles and reasoning not just facts which are apt to change over time and that one should teach first about people not machines or techniques.')\n",
      "bye\n",
      "Chatbot: Most welcome\n",
      "Chatbot: Take care, bye ..\n"
     ]
    }
   ],
   "source": [
    "#sample \n",
    "output_greetings=[\"thanks\",\"thank you very much\",\"thank you\",\"bye\"]\n",
    "print(\"Hello, I am a chatbot and will answer your queries regarding the article:\") #greet user\n",
    "continue_discussion=True\n",
    "while continue_discussion==True:\n",
    "    user_input = input() #get user input\n",
    "    user_input = user_input .lower()\n",
    "    if user_input in output_greetings or user_input =='':\n",
    "            continue_discussion=False\n",
    "            print(\"Chatbot: Most welcome\")\n",
    "    elif reply_greeting(user_input)!=None:\n",
    "                print(\"Chatbot: \"+reply_greeting(user_input))\n",
    "    else:\n",
    "        print(\"Chatbot: \",end=\"\")\n",
    "        print(give_reply(user_input))\n",
    "print(\"Chatbot: Take care, bye ..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
